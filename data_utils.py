# -*- coding: utf-8 -*-
"""data_utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k704Cb5TdEqd6jVM5rJFjJwB5oKLbhcH
"""

"""
data_utils.py

Data loading, augmentation, batching and evaluation metrics
for wrist anomaly classification.

Contents:
  - SingleImageDataset
  - train_transforms / val_transforms
  - collate_fn
  - compute_metrics

All model definitions (CNN backbones, ViT backbones, hybrid
fusion models, partial-freezing utilities) live in
hybrid_vision.py and should NOT be duplicated here.
"""

from typing import Optional, Tuple
import numpy as np
import torch
from torch.utils.data import Dataset
from torchvision import transforms
from PIL import Image
from sklearn.metrics import accuracy_score, recall_score, roc_auc_score


class SingleImageDataset(Dataset):
    """
    Minimal dataset wrapper for binary classification on wrist X-rays.

    Accepts image arrays with shapes:
      [H, W] grayscale
      [H, W, 1] or [H, W, 3]
      [C, H, W] where C is 1 or 3
      [N, ...] if you're passing a batch externally

    labels should be 0/1 or float-castable.

    transform should map a PIL.Image -> torch.FloatTensor [3, 224, 224].
    """

    def __init__(self, images, labels, transform: Optional[transforms.Compose] = None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self) -> int:
        return len(self.images)

    def _to_pil(self, arr) -> Image.Image:
        """
        Convert an array or tensor to a 3-channel uint8 PIL image.
        """
        if isinstance(arr, torch.Tensor):
            arr = arr.detach().cpu().numpy()

        # Make channels last, RGB
        if arr.ndim == 2:
            # [H, W] -> [H, W, 3]
            arr = np.stack([arr, arr, arr], axis=-1)
        elif arr.ndim == 3 and arr.shape[0] in (1, 3):
            # [C, H, W] -> [H, W, C]
            arr = np.transpose(arr, (1, 2, 0))
        elif arr.ndim == 3 and arr.shape[-1] == 1:
            # [H, W, 1] -> [H, W, 3]
            arr = np.repeat(arr, 3, axis=-1)
        elif arr.ndim != 3:
            raise ValueError(f"Unexpected image shape: {arr.shape}")

        # Ensure uint8 for PIL
        if np.issubdtype(arr.dtype, np.floating):
            if arr.max() <= 1.0:
                arr = (arr * 255.0).astype(np.uint8)
            else:
                arr = arr.astype(np.uint8)
        elif arr.dtype != np.uint8:
            arr = arr.astype(np.uint8)

        return Image.fromarray(arr)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        img = self.images[idx]
        label = self.labels[idx]

        img = self._to_pil(img)
        if self.transform:
            img = self.transform(img)

        # binary classification target
        label = torch.tensor([float(label)], dtype=torch.float32)

        return img, label


# -------------------------------------------------
# Data augmentation / preprocessing
# -------------------------------------------------

train_transforms = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(
        brightness=0.2,
        contrast=0.2,
        saturation=0.2,
        hue=0.1
    ),
    transforms.ToTensor(),

])

val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),

])


# -------------------------------------------------
# Collate helpers for DataLoader
# -------------------------------------------------

def collate_fn(batch):
    """
    Collate [(img_tensor, label_tensor), ...] into a dict
    that matches what the hybrid models expect.
    """
    imgs, labels = zip(*batch)
    imgs = torch.stack(imgs)         # [B, 3, 224, 224]
    labels = torch.stack(labels)     # [B, 1]
    return {"pixel_values": imgs, "labels": labels}


# -------------------------------------------------
# Metrics for evaluation / validation
# -------------------------------------------------

def compute_metrics(eval_pred):
    """
    Compute standard metrics:
    - accuracy
    - recall (sensitivity on the positive class)
    - ROC AUC

    eval_pred can be:
      (logits, labels)
      or an object with .predictions and .label_ids
      (for example, HuggingFace Trainer EvalPrediction)
    """
    if isinstance(eval_pred, tuple):
        logits, labels = eval_pred
    else:
        logits = eval_pred.predictions
        labels = eval_pred.label_ids

    logits = np.asarray(logits).squeeze()         # [N] or [N,1] -> [N]
    labels = np.asarray(labels).reshape(-1)       # [N]

    probs = 1.0 / (1.0 + np.exp(-logits))         # sigmoid
    preds = (probs >= 0.5).astype(int)

    acc = accuracy_score(labels, preds)
    rec = recall_score(labels, preds)             # positive class recall

    try:
        auc = roc_auc_score(labels, probs)        # uses probabilities
    except ValueError:
        # AUC fails if only one class is present
        auc = float("nan")

    return {
        "accuracy": acc,
        "recall": rec,
        "auc": auc,
    }